{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Modelos de clasificación\n",
    "## Regresión logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "\n",
    "Para desarrollar un regresión logística en Python podemos hacer uso de dos librerías unna de ellas es **statsmodels**, usaremos el dataset **Titanic** que usamos en clases anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels as model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la carga de los datos podemos quitar aquellas columnas que no serán de interes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"data/titanic.csv\").drop([\"name\", \"ticket\", \"cabin\", \n",
    "                                                                \"boat\", \"body\", \"home.dest\"], \n",
    "                                                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.groupby(\"survived\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.groupby(\"survived\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.factorplot('sex',data=df_titanic,kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.factorplot('pclass', data=df_titanic, hue='survived', kind=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.factorplot('embarked',data=df_titanic,hue='survived',kind=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.boxplot(x=\"pclass\", y=\"fare\", hue = \"survived\", data=df_titanic, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(df_titanic, hue=\"survived\", palette=\"husl\",  aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre debemos tener en cuenta los tipos de variables con las cuales trabajaremos. De ser necesario cambiar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.pclass=df_titanic.pclass.astype('category',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_numericos = df_titanic.select_dtypes(include=['float64', \"int64\"])\n",
    "datos_categoricos = df_titanic.select_dtypes(exclude=['float64', \"int64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_titanic.age.fillna(df_titanic.age.mean(), inplace=True)\n",
    "#df_titanic.fare.fillna(df_titanic.fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in datos_numericos.columns:\n",
    "    datos_numericos[col].fillna(datos_numericos[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos_categoricos_codificados = pd.get_dummies(datos_categoricos, drop_first=True)\n",
    "datos_categoricos_codificados = pd.get_dummies(datos_categoricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_final = pd.concat([datos_numericos, datos_categoricos_codificados], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_final = df_titanic_final.drop([\"pclass_2\", \"pclass_3\", \"sex_male\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_titanic_final.drop('survived', axis=1)\n",
    "y=df_titanic_final['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model=sm.Logit(y,X, iter = 10)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df_titanic['sex'] =='male', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic['pclass']=np.where(df_titanic['pclass'] ==1, 1, 0)\n",
    "df_titanic['sex_female']=np.where(df_titanic['sex'] =='female', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_2 = df_titanic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_2=df_titanic_2.drop([\"sex\", \"parch\", \"embarked\", \"fare\"], axis = 1)\n",
    "df_titanic_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_titanic_2.columns:\n",
    "    df_titanic_2[col].fillna(df_titanic_2[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_titanic_2.drop(\"survived\", axis=1)\n",
    "y=df_titanic_2['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic_2.groupby(\"survived\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con el módulo de Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos `LogisticRegression` del modulo **linear_model**  del **sklearn** para ejecutar la regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos `metrics` del **sklearn** para obtener las princiaples métricas de evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos `train_test_split` del modulo **model_selection** para obtener los datos de entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos nuestros datos y ajustamos un modelo de regresión logística. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "estimador_logis = LogisticRegression()\n",
    "estimador_logis.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = estimador_logis.predict(X_test)\n",
    "\n",
    "predicciones[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_probabilidades = estimador_logis.predict_proba(X_test)\n",
    "predicciones_probabilidades[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicciones_probabilidades);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df = pd.DataFrame(predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = X_test.reset_index().copy()\n",
    "df_resultados[\"objetivo\"] = y_test.tolist()\n",
    "df_resultados[\"prediccion\"] = predicciones\n",
    "df_resultados = pd.concat([df_resultados, probs_df], axis=1)\n",
    "df_resultados[[\"objetivo\", \"prediccion\", 0, 1]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"clase_real\":y_test,\n",
    "                   \"clase_pred\": predicciones,\n",
    "                   \"probabilidades_0\":estimador_logis.predict_proba(X_test)[:,0],\n",
    "                    \"probabilidades_1\":estimador_logis.predict_proba(X_test)[:,1],\n",
    "                  })\n",
    "df[\"sum_probas\"] = df.probabilidades_0 + df.probabilidades_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"probabilidades_1>0.4 & clase_pred==0\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"probabilidades_0>0.5 & clase_pred==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidades_a_clases(predicciones_probabilidades, umbral=0.5):\n",
    "    predicciones = np.zeros([len(predicciones_probabilidades), ])\n",
    "    predicciones[predicciones_probabilidades[:,1]>=umbral] = 1\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_probabilidades[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_a_clases(predicciones_probabilidades, umbral=0.40)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = probabilidades_a_clases(predicciones_probabilidades, umbral=0.40)\n",
    "confusion_matrix(y_test, pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_en_umbral = probabilidades_a_clases(predicciones_probabilidades, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensibilidad_umbral = metrics.recall_score(y_test, predicciones_en_umbral)\n",
    "sensibilidad_umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_umbral = metrics.average_precision_score(y_test, predicciones_en_umbral)\n",
    "precision_umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, fixed, interact\n",
    "@interact(umbral=widgets.FloatSlider(min=0.001, max=0.999, step=0.001, value=0.001))\n",
    "def evaluar_umbral(umbral):\n",
    "    predicciones_en_umbral = probabilidades_a_clases(predicciones_probabilidades, umbral)\n",
    "    sensibilidad_umbral = metrics.recall_score(y_test, predicciones_en_umbral)\n",
    "    precision_umbral = metrics.average_precision_score(y_test, predicciones_en_umbral)\n",
    "    exactitud_umbral = metrics.accuracy_score(y_test, predicciones_en_umbral)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, predicciones_en_umbral)\n",
    "    mc_umbral = confusion_matrix(y_test, predicciones_en_umbral)\n",
    "    print( \"\"\"\n",
    "    Precision: {:.3f}\n",
    "    Sensibilidad:{:.3f}\n",
    "    Exacitud:{:.3f}\n",
    "    Area_ROC:{:.3F}\n",
    "    \"\"\".format(\n",
    "        precision_umbral,\n",
    "        sensibilidad_umbral,\n",
    "        exactitud_umbral,\n",
    "        roc_auc\n",
    "    ))\n",
    "    print(\"Matriz de confusión\")\n",
    "    print(mc_umbral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_umbral(umbral):\n",
    "    predicciones_en_umbral = probabilidades_a_clases(predicciones_probabilidades, umbral)\n",
    "    precision_umbral =  metrics.average_precision_score(y_test, predicciones_en_umbral)\n",
    "    sensibilidad_umbral = metrics.recall_score(y_test, predicciones_en_umbral)\n",
    "    return precision_umbral, sensibilidad_umbral\n",
    "\n",
    "\n",
    "rango_umbral = np.linspace(0., 1., 1000)\n",
    "sensibilidad_umbrales = []\n",
    "precision_umbrales = []\n",
    "\n",
    "for umbral in rango_umbral:\n",
    "    precision_umbral, sensibilidad_umbral = evaluar_umbral(umbral)\n",
    "    precision_umbrales.append(precision_umbral)\n",
    "    sensibilidad_umbrales.append(sensibilidad_umbral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sensibilidad_umbrales, precision_umbrales);\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Ratio de Verdaderos positivos (sensibilidad)\")\n",
    "plt.title(\"Curva Precision-Recall\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, estimador_logis.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, estimador_logis.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(clases_reales, predicciones, probabilidades):\n",
    "    exactitud = metrics.accuracy_score(clases_reales, predicciones)\n",
    "    precision = metrics.average_precision_score(clases_reales, predicciones)\n",
    "    sensibilidad = metrics.recall_score(clases_reales, predicciones)\n",
    "    roc_auc = metrics.roc_auc_score(clases_reales, predicciones)\n",
    "    f1 = metrics.f1_score(clases_reales, predicciones)\n",
    "    print(\"\"\"\n",
    "    Exactitud: {:.3f}\n",
    "    Precisión: {:.3f}\n",
    "    Sensibilidad: {:.3f}\n",
    "    Area bajo curva (AUC): {:.3f}\n",
    "    Puntuación F1: {:.3f}\n",
    "    \"\"\".format(\n",
    "        exactitud, \n",
    "        precision,\n",
    "        sensibilidad,\n",
    "        roc_auc,\n",
    "        f1\n",
    "    ))\n",
    "    \n",
    "evaluar_modelo(y_test, predicciones, predicciones_probabilidades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
