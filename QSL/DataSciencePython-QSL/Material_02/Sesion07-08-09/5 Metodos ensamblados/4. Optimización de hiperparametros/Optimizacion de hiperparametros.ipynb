{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "____\n",
    "![revit](https://i.ibb.co/bQ3dB8C/curso-revit.png)\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "\n",
    "# Clase 07\n",
    "## Tunning de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimización de hiperparámetros\n",
    "\n",
    "Hasta ahora hemos visto una manera relativamente sencilla de ver que valores de los hiperparámetros funcionan mejor, mediante las curvas de validación.\n",
    "\n",
    "Estas curvas son muy útiles para darnos información a los Data Scientists, pero tienen dos problemas:\n",
    "- Son métodos gráficos, esto significa que necesitan un humano para interpretarlas y no nos permiten automatizar el proceso para encontrar los hiperparámetros óptimos.\n",
    "- Solo toman un hiperparámetro a la vez. Esto significa que hacen que sea más dificil el evaluar combinaciones de los hiperparámetros (si quisieramos evaluar multiples hiperparámetros tendriamos que hacer gráficas de planos o hiperplanos).\n",
    "\n",
    "Vamos a ver ahora métodos más robustos para dado un modelo, encontrar el conjunto de hiperparámetros que hace que funcione mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos los datos\n",
    "\n",
    "Vamos a usar un dataset nuevo, el [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income). Es un dataset que tiene datos demográficos sobre 50,000 personas en Estados Unidos y como variable objetivo tiene una variable booleana (Verdadero/Falso) sobre si dicha persona gana más de 50K$ al año o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo = pd.read_csv(\"data/salario_censo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edad</th>\n",
       "      <th>clase_laboral</th>\n",
       "      <th>nivel_educativo</th>\n",
       "      <th>status_matrimonial</th>\n",
       "      <th>ocupacion</th>\n",
       "      <th>relacion</th>\n",
       "      <th>raza</th>\n",
       "      <th>genero</th>\n",
       "      <th>ganancias_capital</th>\n",
       "      <th>perdidas_capital</th>\n",
       "      <th>horas_laborables</th>\n",
       "      <th>pais_origen</th>\n",
       "      <th>objetivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edad      clase_laboral  nivel_educativo   status_matrimonial  \\\n",
       "0    39          State-gov               13        Never-married   \n",
       "1    50   Self-emp-not-inc               13   Married-civ-spouse   \n",
       "2    38            Private                9             Divorced   \n",
       "3    53            Private                7   Married-civ-spouse   \n",
       "4    28            Private               13   Married-civ-spouse   \n",
       "\n",
       "            ocupacion        relacion    raza   genero  ganancias_capital  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male               2174   \n",
       "1     Exec-managerial         Husband   White     Male                  0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male                  0   \n",
       "3   Handlers-cleaners         Husband   Black     Male                  0   \n",
       "4      Prof-specialty            Wife   Black   Female                  0   \n",
       "\n",
       "   perdidas_capital  horas_laborables     pais_origen objetivo  \n",
       "0                 0                40   United-States    <=50K  \n",
       "1                 0                13   United-States    <=50K  \n",
       "2                 0                40   United-States    <=50K  \n",
       "3                 0                40   United-States    <=50K  \n",
       "4                 0                40            Cuba    <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_dependiente = \"objetivo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inicial = censo.drop(variable_dependiente, axis =1)\n",
    "y = censo[variable_dependiente]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso la variable objetivo está definida como texto, asi que la convertimos a una variable binaria numérica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({\" <=50K\":0, \" >50K\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos datos en numéricos y no numéricos. Viendo el [diccionario de datos](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names) del dataset vemos que no hay variables categóricas, solo la variable educacion que ya viene codificada como numérica (*education-num*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5434: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# Separamos los datos numéricos y categóricos\n",
    "datos_numericos = X_inicial.select_dtypes(include=['float64', \"int64\"])\n",
    "datos_categoricos = X_inicial.select_dtypes(exclude=['float64', \"int64\"])\n",
    "\n",
    "# Para los missing numéricos los imputamos con la media\n",
    "for col in datos_numericos.columns:\n",
    "    datos_numericos[col].fillna(datos_numericos[col].mean(), inplace=True)\n",
    "\n",
    "# Para los categoricos creamos dummies\n",
    "datos_categoricos_codificados = pd.get_dummies(datos_categoricos)\n",
    "X = pd.concat([datos_numericos, datos_categoricos_codificados], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 91)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes que nada vamos a ver que puntuaciones tienen unos cuantos modelos con sus  hiperparámetro por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def evaluar_modelo(estimador, X, y):\n",
    "    resultados_estimador = cross_validate(estimador, X, y,\n",
    "                     scoring=\"roc_auc\", n_jobs=-1, cv=5, return_train_score=True)\n",
    "    return resultados_estimador\n",
    "\n",
    "def ver_resultados():\n",
    "    resultados_df  = pd.DataFrame(resultados).T\n",
    "    resultados_cols = resultados_df.columns\n",
    "    for col in resultados_df:\n",
    "        resultados_df[col] = resultados_df[col].apply(np.mean)\n",
    "        resultados_df[col+\"_idx\"] = resultados_df[col] / resultados_df[col].max()\n",
    "    return resultados_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_logistica\"] = evaluar_modelo(LogisticRegression(), X, y)\n",
    "resultados[\"naive_bayes\"] = evaluar_modelo(GaussianNB(), X, y)\n",
    "resultados[\"rf\"] = evaluar_modelo(RandomForestClassifier(), X, y)\n",
    "resultados[\"svc\"] = evaluar_modelo(SVC(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>fit_time_idx</th>\n",
       "      <th>score_time_idx</th>\n",
       "      <th>test_score_idx</th>\n",
       "      <th>train_score_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>reg_logistica</th>\n",
       "      <td>0.582841</td>\n",
       "      <td>0.013370</td>\n",
       "      <td>0.905177</td>\n",
       "      <td>0.906081</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.141620</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>0.888876</td>\n",
       "      <td>0.889217</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.981992</td>\n",
       "      <td>0.893276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.627322</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.874810</td>\n",
       "      <td>0.995456</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.966452</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>100.482281</td>\n",
       "      <td>13.401541</td>\n",
       "      <td>0.888096</td>\n",
       "      <td>0.910491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981130</td>\n",
       "      <td>0.914647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fit_time  score_time  test_score  train_score  fit_time_idx  \\\n",
       "reg_logistica    0.582841    0.013370    0.905177     0.906081      0.005800   \n",
       "naive_bayes      0.141620    0.037100    0.888876     0.889217      0.001409   \n",
       "rf               0.627322    0.035510    0.874810     0.995456      0.006243   \n",
       "svc            100.482281   13.401541    0.888096     0.910491      1.000000   \n",
       "\n",
       "               score_time_idx  test_score_idx  train_score_idx  \n",
       "reg_logistica        0.000998        1.000000         0.910218  \n",
       "naive_bayes          0.002768        0.981992         0.893276  \n",
       "rf                   0.002650        0.966452         1.000000  \n",
       "svc                  1.000000        0.981130         0.914647  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_resultados()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a seleccionar un estimador en función de los resultados iniciales y optimizarlo. Elijo el estimador Random Forest por que funciona muy bien en comparación a los demás y es bastánte rápido de entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimador_rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn tiene dos métodos de optimización de hiperparámetros, [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) y [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV).\n",
    "\n",
    "`GridSearchCV` funciona realizando una busqueda en una malla, es decir, pasandole un conjunto de posibles opciones de hiperparámetros evalua de forma completa cada combinación de dichos parámetros (es decir, el valor 1 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, el valor 2 del hiperparámetro 1 combinado con todos los posibles valores de los demás hiperparámetros, etcétera).\n",
    "\n",
    "La ventaja de utilizar una búsqueda de malla es que nos aseguramos de que se han probado todas las combinaciones posibles. El problema es que el proceso requiere mucho tiempo de computación, y según que dataset usemos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 ns ± 5.35 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import time\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 ns ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1  #n 1 dice que ejecute esta celda solo una vez, -r 1 que ejecute un solo loop\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A random forest classifier.\n",
      "\n",
      "    A random forest is a meta estimator that fits a number of decision tree\n",
      "    classifiers on various sub-samples of the dataset and uses averaging to\n",
      "    improve the predictive accuracy and control over-fitting.\n",
      "    The sub-sample size is always the same as the original\n",
      "    input sample size but the samples are drawn with replacement if\n",
      "    `bootstrap=True` (default).\n",
      "\n",
      "    Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    n_estimators : integer, optional (default=10)\n",
      "        The number of trees in the forest.\n",
      "\n",
      "        .. versionchanged:: 0.20\n",
      "           The default value of ``n_estimators`` will change from 10 in\n",
      "           version 0.20 to 100 in version 0.22.\n",
      "\n",
      "    criterion : string, optional (default=\"gini\")\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "        Note: this parameter is tree-specific.\n",
      "\n",
      "    max_depth : integer or None, optional (default=None)\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int, float, optional (default=2)\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int, float, optional (default=1)\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, optional (default=0.)\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float, string or None, optional (default=\"auto\")\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a fraction and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "        - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      "        - If \"log2\", then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    max_leaf_nodes : int or None, optional (default=None)\n",
      "        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, optional (default=0.)\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, (default=1e-7)\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "\n",
      "    bootstrap : boolean, optional (default=True)\n",
      "        Whether bootstrap samples are used when building trees.\n",
      "\n",
      "    oob_score : bool (default=False)\n",
      "        Whether to use out-of-bag samples to estimate\n",
      "        the generalization accuracy.\n",
      "\n",
      "    n_jobs : int or None, optional (default=None)\n",
      "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
      "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "        for more details.\n",
      "\n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    verbose : int, optional (default=0)\n",
      "        Controls the verbosity when fitting and predicting.\n",
      "\n",
      "    warm_start : bool, optional (default=False)\n",
      "        When set to ``True``, reuse the solution of the previous call to fit\n",
      "        and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "        new forest. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "    class_weight : dict, list of dicts, \"balanced\", \"balanced_subsample\" or     None, optional (default=None)\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If not given, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      "        weights are computed based on the bootstrap sample for every tree\n",
      "        grown.\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    estimators_ : list of DecisionTreeClassifier\n",
      "        The collection of fitted sub-estimators.\n",
      "\n",
      "    classes_ : array of shape = [n_classes] or a list of such arrays\n",
      "        The classes labels (single output problem), or a list of arrays of\n",
      "        class labels (multi-output problem).\n",
      "\n",
      "    n_classes_ : int or list\n",
      "        The number of classes (single output problem), or a list containing the\n",
      "        number of classes for each output (multi-output problem).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    feature_importances_ : array of shape = [n_features]\n",
      "        The feature importances (the higher, the more important the feature).\n",
      "\n",
      "    oob_score_ : float\n",
      "        Score of the training dataset obtained using an out-of-bag estimate.\n",
      "\n",
      "    oob_decision_function_ : array of shape = [n_samples, n_classes]\n",
      "        Decision function computed with out-of-bag estimate on the training\n",
      "        set. If n_estimators is small it might be possible that a data point\n",
      "        was never left out during the bootstrap. In this case,\n",
      "        `oob_decision_function_` might contain NaN.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.ensemble import RandomForestClassifier\n",
      "    >>> from sklearn.datasets import make_classification\n",
      "\n",
      "    >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "    ...                            n_informative=2, n_redundant=0,\n",
      "    ...                            random_state=0, shuffle=False)\n",
      "    >>> clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
      "    ...                              random_state=0)\n",
      "    >>> clf.fit(X, y)\n",
      "    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
      "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                min_samples_leaf=1, min_samples_split=2,\n",
      "                min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "                oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "    >>> print(clf.feature_importances_)\n",
      "    [0.14205973 0.76664038 0.0282433  0.06305659]\n",
      "    >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "    [1]\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data,\n",
      "    ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "    of the criterion is identical for several splits enumerated during the\n",
      "    search of the best split. To obtain a deterministic behaviour during\n",
      "    fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      "    See also\n",
      "    --------\n",
      "    DecisionTreeClassifier, ExtraTreesClassifier\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(estimador_rf.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador_rf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a definir los límites de la búsqueda de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,  120,  230,  340,  450,  560,  670,  780,  890, 1000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(10,1000,10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-156b1f5c303c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m parametros_busqueda_rf = {\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"criterion\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;34m\"n_estimators\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;34m\"class_weight\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "parametros_busqueda_rf = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=estimador_rf, \n",
    "                    param_grid=parametros_busqueda_rf,\n",
    "                    scoring=\"roc_auc\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` se comporta como un estimador en cuanto a que tiene un metodo fit que usamos para \"entrenarlo\" y que realize la búsqueda en malla.\n",
    "\n",
    "Para ver cuanto tiempo tarda en realizar la búsqueda usamos la mágia de Jupyter notebook `%%timeit` que evalua el tiempo que tarda una función en ejecutarse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27min 21s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi ordenador la busqueda en malla ha tardado 7minutos y 49 segundos \n",
    "\n",
    "Ahora podemos ver la puntuación que ha obtenido el mejor estimador así como los parámetros del mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973525008870069\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=890, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras haberlo ajustado, Gridsearch nos devuelve el ranking de todas las variantes evaluadas junto con métricas de su funcionamiento con el atributo `cv_results_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>73.756554</td>\n",
       "      <td>0.762596</td>\n",
       "      <td>6.522890</td>\n",
       "      <td>0.166150</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894167</td>\n",
       "      <td>0.896621</td>\n",
       "      <td>0.901270</td>\n",
       "      <td>0.897353</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.998036</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>83.158527</td>\n",
       "      <td>1.006302</td>\n",
       "      <td>7.345021</td>\n",
       "      <td>0.233350</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894558</td>\n",
       "      <td>0.896468</td>\n",
       "      <td>0.901017</td>\n",
       "      <td>0.897347</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998220</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>0.998026</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46.816092</td>\n",
       "      <td>0.754700</td>\n",
       "      <td>4.174504</td>\n",
       "      <td>0.046624</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894559</td>\n",
       "      <td>0.896735</td>\n",
       "      <td>0.900441</td>\n",
       "      <td>0.897245</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.998135</td>\n",
       "      <td>0.998015</td>\n",
       "      <td>0.998123</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57.922133</td>\n",
       "      <td>0.914542</td>\n",
       "      <td>5.393932</td>\n",
       "      <td>0.608828</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894220</td>\n",
       "      <td>0.896379</td>\n",
       "      <td>0.900565</td>\n",
       "      <td>0.897055</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>0.998057</td>\n",
       "      <td>0.998137</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>69.493612</td>\n",
       "      <td>1.245437</td>\n",
       "      <td>5.739948</td>\n",
       "      <td>0.178525</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894438</td>\n",
       "      <td>0.895837</td>\n",
       "      <td>0.900510</td>\n",
       "      <td>0.896928</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>5</td>\n",
       "      <td>0.998220</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38.281744</td>\n",
       "      <td>0.498377</td>\n",
       "      <td>3.130282</td>\n",
       "      <td>0.075287</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.894409</td>\n",
       "      <td>0.896068</td>\n",
       "      <td>0.900281</td>\n",
       "      <td>0.896919</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998123</td>\n",
       "      <td>0.998014</td>\n",
       "      <td>0.998118</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64.935093</td>\n",
       "      <td>2.875777</td>\n",
       "      <td>6.428460</td>\n",
       "      <td>0.559175</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893962</td>\n",
       "      <td>0.896232</td>\n",
       "      <td>0.900200</td>\n",
       "      <td>0.896798</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998233</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.998057</td>\n",
       "      <td>0.998145</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>62.566500</td>\n",
       "      <td>0.717926</td>\n",
       "      <td>5.724939</td>\n",
       "      <td>0.092034</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.894605</td>\n",
       "      <td>0.895841</td>\n",
       "      <td>0.899921</td>\n",
       "      <td>0.896789</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>8</td>\n",
       "      <td>0.997586</td>\n",
       "      <td>0.997522</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>0.997386</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.999356</td>\n",
       "      <td>0.201989</td>\n",
       "      <td>5.053727</td>\n",
       "      <td>0.026956</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893907</td>\n",
       "      <td>0.896036</td>\n",
       "      <td>0.900377</td>\n",
       "      <td>0.896773</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998235</td>\n",
       "      <td>0.998160</td>\n",
       "      <td>0.998052</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.667451</td>\n",
       "      <td>0.231628</td>\n",
       "      <td>7.569657</td>\n",
       "      <td>0.101920</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.894186</td>\n",
       "      <td>0.895625</td>\n",
       "      <td>0.900408</td>\n",
       "      <td>0.896740</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998222</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.998031</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80.521067</td>\n",
       "      <td>2.142527</td>\n",
       "      <td>6.421472</td>\n",
       "      <td>0.465126</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893984</td>\n",
       "      <td>0.896049</td>\n",
       "      <td>0.899957</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>11</td>\n",
       "      <td>0.997612</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.997057</td>\n",
       "      <td>0.997400</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38.821167</td>\n",
       "      <td>0.043182</td>\n",
       "      <td>3.492659</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893500</td>\n",
       "      <td>0.895948</td>\n",
       "      <td>0.900375</td>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>12</td>\n",
       "      <td>0.998212</td>\n",
       "      <td>0.998163</td>\n",
       "      <td>0.998043</td>\n",
       "      <td>0.998139</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46.202713</td>\n",
       "      <td>0.187040</td>\n",
       "      <td>4.419874</td>\n",
       "      <td>0.097655</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893148</td>\n",
       "      <td>0.895994</td>\n",
       "      <td>0.900565</td>\n",
       "      <td>0.896569</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>13</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>0.998057</td>\n",
       "      <td>0.998140</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>73.430983</td>\n",
       "      <td>0.690302</td>\n",
       "      <td>6.583541</td>\n",
       "      <td>0.110608</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.894061</td>\n",
       "      <td>0.895996</td>\n",
       "      <td>0.899446</td>\n",
       "      <td>0.896501</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>14</td>\n",
       "      <td>0.997599</td>\n",
       "      <td>0.997565</td>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.997412</td>\n",
       "      <td>0.000241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27.942050</td>\n",
       "      <td>1.488764</td>\n",
       "      <td>2.902786</td>\n",
       "      <td>0.440148</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.893540</td>\n",
       "      <td>0.895153</td>\n",
       "      <td>0.900702</td>\n",
       "      <td>0.896465</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>0.998137</td>\n",
       "      <td>0.998007</td>\n",
       "      <td>0.998110</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.397238</td>\n",
       "      <td>0.333572</td>\n",
       "      <td>2.207121</td>\n",
       "      <td>0.110492</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893585</td>\n",
       "      <td>0.894992</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.896390</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>16</td>\n",
       "      <td>0.998217</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>0.997994</td>\n",
       "      <td>0.998105</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54.265598</td>\n",
       "      <td>0.716597</td>\n",
       "      <td>4.695212</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.895680</td>\n",
       "      <td>0.899895</td>\n",
       "      <td>0.896342</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>17</td>\n",
       "      <td>0.997618</td>\n",
       "      <td>0.997529</td>\n",
       "      <td>0.997074</td>\n",
       "      <td>0.997407</td>\n",
       "      <td>0.000238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46.307071</td>\n",
       "      <td>0.218544</td>\n",
       "      <td>4.015930</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893782</td>\n",
       "      <td>0.895779</td>\n",
       "      <td>0.899445</td>\n",
       "      <td>0.896335</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>18</td>\n",
       "      <td>0.997588</td>\n",
       "      <td>0.997556</td>\n",
       "      <td>0.997006</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.939356</td>\n",
       "      <td>0.471389</td>\n",
       "      <td>2.801816</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.893269</td>\n",
       "      <td>0.895688</td>\n",
       "      <td>0.900008</td>\n",
       "      <td>0.896321</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>19</td>\n",
       "      <td>0.998234</td>\n",
       "      <td>0.998133</td>\n",
       "      <td>0.998063</td>\n",
       "      <td>0.998143</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>39.324322</td>\n",
       "      <td>0.592776</td>\n",
       "      <td>3.207404</td>\n",
       "      <td>0.038482</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893695</td>\n",
       "      <td>0.895978</td>\n",
       "      <td>0.899012</td>\n",
       "      <td>0.896228</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997561</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.997039</td>\n",
       "      <td>0.997369</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.463277</td>\n",
       "      <td>0.262393</td>\n",
       "      <td>1.604043</td>\n",
       "      <td>0.083767</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.893371</td>\n",
       "      <td>0.895487</td>\n",
       "      <td>0.899561</td>\n",
       "      <td>0.896139</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>21</td>\n",
       "      <td>0.998169</td>\n",
       "      <td>0.998089</td>\n",
       "      <td>0.997965</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>19.284361</td>\n",
       "      <td>0.137028</td>\n",
       "      <td>1.645364</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893506</td>\n",
       "      <td>0.895394</td>\n",
       "      <td>0.899382</td>\n",
       "      <td>0.896094</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>22</td>\n",
       "      <td>0.997497</td>\n",
       "      <td>0.997456</td>\n",
       "      <td>0.996982</td>\n",
       "      <td>0.997311</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>29.871594</td>\n",
       "      <td>0.609894</td>\n",
       "      <td>2.651709</td>\n",
       "      <td>0.070167</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.893517</td>\n",
       "      <td>0.895313</td>\n",
       "      <td>0.899130</td>\n",
       "      <td>0.895987</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>23</td>\n",
       "      <td>0.997509</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.997003</td>\n",
       "      <td>0.997350</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60.845609</td>\n",
       "      <td>0.871403</td>\n",
       "      <td>5.988223</td>\n",
       "      <td>0.199009</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>780</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893247</td>\n",
       "      <td>0.895409</td>\n",
       "      <td>0.899158</td>\n",
       "      <td>0.895938</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>24</td>\n",
       "      <td>0.997605</td>\n",
       "      <td>0.997531</td>\n",
       "      <td>0.997038</td>\n",
       "      <td>0.997391</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>70.154079</td>\n",
       "      <td>1.084483</td>\n",
       "      <td>6.338482</td>\n",
       "      <td>0.278392</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>890</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893587</td>\n",
       "      <td>0.895243</td>\n",
       "      <td>0.898935</td>\n",
       "      <td>0.895922</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>25</td>\n",
       "      <td>0.997576</td>\n",
       "      <td>0.997559</td>\n",
       "      <td>0.997044</td>\n",
       "      <td>0.997393</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.479914</td>\n",
       "      <td>0.455120</td>\n",
       "      <td>1.535228</td>\n",
       "      <td>0.060677</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>0.895552</td>\n",
       "      <td>0.899388</td>\n",
       "      <td>0.895881</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>26</td>\n",
       "      <td>0.998192</td>\n",
       "      <td>0.998102</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>78.807214</td>\n",
       "      <td>0.672332</td>\n",
       "      <td>7.388524</td>\n",
       "      <td>0.282908</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893142</td>\n",
       "      <td>0.895500</td>\n",
       "      <td>0.898919</td>\n",
       "      <td>0.895853</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>27</td>\n",
       "      <td>0.997628</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>0.997054</td>\n",
       "      <td>0.997409</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>37.207938</td>\n",
       "      <td>0.320305</td>\n",
       "      <td>3.361080</td>\n",
       "      <td>0.119038</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>450</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893242</td>\n",
       "      <td>0.894980</td>\n",
       "      <td>0.898861</td>\n",
       "      <td>0.895695</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>28</td>\n",
       "      <td>0.997582</td>\n",
       "      <td>0.997527</td>\n",
       "      <td>0.996987</td>\n",
       "      <td>0.997365</td>\n",
       "      <td>0.000269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50.635502</td>\n",
       "      <td>0.560427</td>\n",
       "      <td>4.783543</td>\n",
       "      <td>0.110395</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>670</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893107</td>\n",
       "      <td>0.895213</td>\n",
       "      <td>0.898707</td>\n",
       "      <td>0.895676</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>29</td>\n",
       "      <td>0.997602</td>\n",
       "      <td>0.997551</td>\n",
       "      <td>0.997068</td>\n",
       "      <td>0.997407</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>43.529338</td>\n",
       "      <td>0.531032</td>\n",
       "      <td>3.922435</td>\n",
       "      <td>0.096839</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>560</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892807</td>\n",
       "      <td>0.895269</td>\n",
       "      <td>0.898603</td>\n",
       "      <td>0.895560</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>30</td>\n",
       "      <td>0.997587</td>\n",
       "      <td>0.997531</td>\n",
       "      <td>0.997058</td>\n",
       "      <td>0.997392</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.212044</td>\n",
       "      <td>0.064076</td>\n",
       "      <td>0.875979</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.892158</td>\n",
       "      <td>0.894486</td>\n",
       "      <td>0.899042</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>31</td>\n",
       "      <td>0.998149</td>\n",
       "      <td>0.998056</td>\n",
       "      <td>0.997913</td>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26.399391</td>\n",
       "      <td>0.663557</td>\n",
       "      <td>2.573057</td>\n",
       "      <td>0.181226</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>340</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.893133</td>\n",
       "      <td>0.894003</td>\n",
       "      <td>0.897831</td>\n",
       "      <td>0.894989</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>32</td>\n",
       "      <td>0.997505</td>\n",
       "      <td>0.997506</td>\n",
       "      <td>0.997020</td>\n",
       "      <td>0.997344</td>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>17.560033</td>\n",
       "      <td>0.314486</td>\n",
       "      <td>1.575480</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>230</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.891948</td>\n",
       "      <td>0.894373</td>\n",
       "      <td>0.898310</td>\n",
       "      <td>0.894877</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>33</td>\n",
       "      <td>0.997533</td>\n",
       "      <td>0.997467</td>\n",
       "      <td>0.997037</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.422497</td>\n",
       "      <td>0.019741</td>\n",
       "      <td>0.760987</td>\n",
       "      <td>0.026955</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.891299</td>\n",
       "      <td>0.893946</td>\n",
       "      <td>0.898912</td>\n",
       "      <td>0.894719</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>34</td>\n",
       "      <td>0.998134</td>\n",
       "      <td>0.998067</td>\n",
       "      <td>0.997907</td>\n",
       "      <td>0.998036</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10.150111</td>\n",
       "      <td>0.138117</td>\n",
       "      <td>0.840753</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.891528</td>\n",
       "      <td>0.893168</td>\n",
       "      <td>0.897280</td>\n",
       "      <td>0.893992</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>35</td>\n",
       "      <td>0.997469</td>\n",
       "      <td>0.997402</td>\n",
       "      <td>0.996901</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.351882</td>\n",
       "      <td>0.284392</td>\n",
       "      <td>0.843842</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>120</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.892646</td>\n",
       "      <td>0.892058</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>0.893844</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>36</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.997402</td>\n",
       "      <td>0.996893</td>\n",
       "      <td>0.997254</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794774</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.078790</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'n...</td>\n",
       "      <td>0.869747</td>\n",
       "      <td>0.871263</td>\n",
       "      <td>0.878763</td>\n",
       "      <td>0.873258</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>37</td>\n",
       "      <td>0.996156</td>\n",
       "      <td>0.996127</td>\n",
       "      <td>0.995481</td>\n",
       "      <td>0.995921</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.905910</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.094767</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'entropy',...</td>\n",
       "      <td>0.868823</td>\n",
       "      <td>0.873295</td>\n",
       "      <td>0.877515</td>\n",
       "      <td>0.873211</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>38</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.995992</td>\n",
       "      <td>0.995911</td>\n",
       "      <td>0.995991</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.033435</td>\n",
       "      <td>0.075555</td>\n",
       "      <td>0.094281</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>balanced</td>\n",
       "      <td>entropy</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'ent...</td>\n",
       "      <td>0.870608</td>\n",
       "      <td>0.874652</td>\n",
       "      <td>0.873690</td>\n",
       "      <td>0.872983</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>39</td>\n",
       "      <td>0.995222</td>\n",
       "      <td>0.994677</td>\n",
       "      <td>0.994785</td>\n",
       "      <td>0.994894</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.912225</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.113033</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>balanced</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>{'class_weight': 'balanced', 'criterion': 'gin...</td>\n",
       "      <td>0.870026</td>\n",
       "      <td>0.870171</td>\n",
       "      <td>0.877454</td>\n",
       "      <td>0.872550</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>40</td>\n",
       "      <td>0.994849</td>\n",
       "      <td>0.994716</td>\n",
       "      <td>0.994638</td>\n",
       "      <td>0.994734</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18      73.756554      0.762596         6.522890        0.166150   \n",
       "19      83.158527      1.006302         7.345021        0.233350   \n",
       "15      46.816092      0.754700         4.174504        0.046624   \n",
       "16      57.922133      0.914542         5.393932        0.608828   \n",
       "17      69.493612      1.245437         5.739948        0.178525   \n",
       "14      38.281744      0.498377         3.130282        0.075287   \n",
       "8       64.935093      2.875777         6.428460        0.559175   \n",
       "37      62.566500      0.717926         5.724939        0.092034   \n",
       "7       53.999356      0.201989         5.053727        0.026956   \n",
       "9       79.667451      0.231628         7.569657        0.101920   \n",
       "39      80.521067      2.142527         6.421472        0.465126   \n",
       "5       38.821167      0.043182         3.492659        0.033861   \n",
       "6       46.202713      0.187040         4.419874        0.097655   \n",
       "38      73.430983      0.690302         6.583541        0.110608   \n",
       "13      27.942050      1.488764         2.902786        0.440148   \n",
       "3       25.397238      0.333572         2.207121        0.110492   \n",
       "36      54.265598      0.716597         4.695212        0.035318   \n",
       "35      46.307071      0.218544         4.015930        0.040584   \n",
       "4       31.939356      0.471389         2.801816        0.015929   \n",
       "34      39.324322      0.592776         3.207404        0.038482   \n",
       "12      19.463277      0.262393         1.604043        0.083767   \n",
       "32      19.284361      0.137028         1.645364        0.150358   \n",
       "33      29.871594      0.609894         2.651709        0.070167   \n",
       "27      60.845609      0.871403         5.988223        0.199009   \n",
       "28      70.154079      1.084483         6.338482        0.278392   \n",
       "2       17.479914      0.455120         1.535228        0.060677   \n",
       "29      78.807214      0.672332         7.388524        0.282908   \n",
       "24      37.207938      0.320305         3.361080        0.119038   \n",
       "26      50.635502      0.560427         4.783543        0.110395   \n",
       "25      43.529338      0.531032         3.922435        0.096839   \n",
       "11      10.212044      0.064076         0.875979        0.017411   \n",
       "23      26.399391      0.663557         2.573057        0.181226   \n",
       "22      17.560033      0.314486         1.575480        0.017919   \n",
       "1        8.422497      0.019741         0.760987        0.026955   \n",
       "31      10.150111      0.138117         0.840753        0.019837   \n",
       "21       9.351882      0.284392         0.843842        0.004860   \n",
       "0        0.794774      0.002681         0.078790        0.001412   \n",
       "10       0.905910      0.016293         0.094767        0.006515   \n",
       "30       1.033435      0.075555         0.094281        0.006278   \n",
       "20       0.912225      0.004179         0.113033        0.003762   \n",
       "\n",
       "   param_class_weight param_criterion param_n_estimators  \\\n",
       "18               None         entropy                890   \n",
       "19               None         entropy               1000   \n",
       "15               None         entropy                560   \n",
       "16               None         entropy                670   \n",
       "17               None         entropy                780   \n",
       "14               None         entropy                450   \n",
       "8                None            gini                890   \n",
       "37           balanced         entropy                780   \n",
       "7                None            gini                780   \n",
       "9                None            gini               1000   \n",
       "39           balanced         entropy               1000   \n",
       "5                None            gini                560   \n",
       "6                None            gini                670   \n",
       "38           balanced         entropy                890   \n",
       "13               None         entropy                340   \n",
       "3                None            gini                340   \n",
       "36           balanced         entropy                670   \n",
       "35           balanced         entropy                560   \n",
       "4                None            gini                450   \n",
       "34           balanced         entropy                450   \n",
       "12               None         entropy                230   \n",
       "32           balanced         entropy                230   \n",
       "33           balanced         entropy                340   \n",
       "27           balanced            gini                780   \n",
       "28           balanced            gini                890   \n",
       "2                None            gini                230   \n",
       "29           balanced            gini               1000   \n",
       "24           balanced            gini                450   \n",
       "26           balanced            gini                670   \n",
       "25           balanced            gini                560   \n",
       "11               None         entropy                120   \n",
       "23           balanced            gini                340   \n",
       "22           balanced            gini                230   \n",
       "1                None            gini                120   \n",
       "31           balanced         entropy                120   \n",
       "21           balanced            gini                120   \n",
       "0                None            gini                 10   \n",
       "10               None         entropy                 10   \n",
       "30           balanced         entropy                 10   \n",
       "20           balanced            gini                 10   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "18  {'class_weight': None, 'criterion': 'entropy',...           0.894167   \n",
       "19  {'class_weight': None, 'criterion': 'entropy',...           0.894558   \n",
       "15  {'class_weight': None, 'criterion': 'entropy',...           0.894559   \n",
       "16  {'class_weight': None, 'criterion': 'entropy',...           0.894220   \n",
       "17  {'class_weight': None, 'criterion': 'entropy',...           0.894438   \n",
       "14  {'class_weight': None, 'criterion': 'entropy',...           0.894409   \n",
       "8   {'class_weight': None, 'criterion': 'gini', 'n...           0.893962   \n",
       "37  {'class_weight': 'balanced', 'criterion': 'ent...           0.894605   \n",
       "7   {'class_weight': None, 'criterion': 'gini', 'n...           0.893907   \n",
       "9   {'class_weight': None, 'criterion': 'gini', 'n...           0.894186   \n",
       "39  {'class_weight': 'balanced', 'criterion': 'ent...           0.893984   \n",
       "5   {'class_weight': None, 'criterion': 'gini', 'n...           0.893500   \n",
       "6   {'class_weight': None, 'criterion': 'gini', 'n...           0.893148   \n",
       "38  {'class_weight': 'balanced', 'criterion': 'ent...           0.894061   \n",
       "13  {'class_weight': None, 'criterion': 'entropy',...           0.893540   \n",
       "3   {'class_weight': None, 'criterion': 'gini', 'n...           0.893585   \n",
       "36  {'class_weight': 'balanced', 'criterion': 'ent...           0.893452   \n",
       "35  {'class_weight': 'balanced', 'criterion': 'ent...           0.893782   \n",
       "4   {'class_weight': None, 'criterion': 'gini', 'n...           0.893269   \n",
       "34  {'class_weight': 'balanced', 'criterion': 'ent...           0.893695   \n",
       "12  {'class_weight': None, 'criterion': 'entropy',...           0.893371   \n",
       "32  {'class_weight': 'balanced', 'criterion': 'ent...           0.893506   \n",
       "33  {'class_weight': 'balanced', 'criterion': 'ent...           0.893517   \n",
       "27  {'class_weight': 'balanced', 'criterion': 'gin...           0.893247   \n",
       "28  {'class_weight': 'balanced', 'criterion': 'gin...           0.893587   \n",
       "2   {'class_weight': None, 'criterion': 'gini', 'n...           0.892704   \n",
       "29  {'class_weight': 'balanced', 'criterion': 'gin...           0.893142   \n",
       "24  {'class_weight': 'balanced', 'criterion': 'gin...           0.893242   \n",
       "26  {'class_weight': 'balanced', 'criterion': 'gin...           0.893107   \n",
       "25  {'class_weight': 'balanced', 'criterion': 'gin...           0.892807   \n",
       "11  {'class_weight': None, 'criterion': 'entropy',...           0.892158   \n",
       "23  {'class_weight': 'balanced', 'criterion': 'gin...           0.893133   \n",
       "22  {'class_weight': 'balanced', 'criterion': 'gin...           0.891948   \n",
       "1   {'class_weight': None, 'criterion': 'gini', 'n...           0.891299   \n",
       "31  {'class_weight': 'balanced', 'criterion': 'ent...           0.891528   \n",
       "21  {'class_weight': 'balanced', 'criterion': 'gin...           0.892646   \n",
       "0   {'class_weight': None, 'criterion': 'gini', 'n...           0.869747   \n",
       "10  {'class_weight': None, 'criterion': 'entropy',...           0.868823   \n",
       "30  {'class_weight': 'balanced', 'criterion': 'ent...           0.870608   \n",
       "20  {'class_weight': 'balanced', 'criterion': 'gin...           0.870026   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "18           0.896621           0.901270         0.897353        0.002945   \n",
       "19           0.896468           0.901017         0.897347        0.002710   \n",
       "15           0.896735           0.900441         0.897245        0.002428   \n",
       "16           0.896379           0.900565         0.897055        0.002634   \n",
       "17           0.895837           0.900510         0.896928        0.002596   \n",
       "14           0.896068           0.900281         0.896919        0.002471   \n",
       "8            0.896232           0.900200         0.896798        0.002578   \n",
       "37           0.895841           0.899921         0.896789        0.002271   \n",
       "7            0.896036           0.900377         0.896773        0.002693   \n",
       "9            0.895625           0.900408         0.896740        0.002660   \n",
       "39           0.896049           0.899957         0.896663        0.002477   \n",
       "5            0.895948           0.900375         0.896608        0.002845   \n",
       "6            0.895994           0.900565         0.896569        0.003055   \n",
       "38           0.895996           0.899446         0.896501        0.002227   \n",
       "13           0.895153           0.900702         0.896465        0.003067   \n",
       "3            0.894992           0.900595         0.896390        0.003028   \n",
       "36           0.895680           0.899895         0.896342        0.002671   \n",
       "35           0.895779           0.899445         0.896335        0.002345   \n",
       "4            0.895688           0.900008         0.896321        0.002787   \n",
       "34           0.895978           0.899012         0.896228        0.002178   \n",
       "12           0.895487           0.899561         0.896139        0.002569   \n",
       "32           0.895394           0.899382         0.896094        0.002449   \n",
       "33           0.895313           0.899130         0.895987        0.002340   \n",
       "27           0.895409           0.899158         0.895938        0.002442   \n",
       "28           0.895243           0.898935         0.895922        0.002235   \n",
       "2            0.895552           0.899388         0.895881        0.002739   \n",
       "29           0.895500           0.898919         0.895853        0.002372   \n",
       "24           0.894980           0.898861         0.895695        0.002349   \n",
       "26           0.895213           0.898707         0.895676        0.002310   \n",
       "25           0.895269           0.898603         0.895560        0.002375   \n",
       "11           0.894486           0.899042         0.895229        0.002859   \n",
       "23           0.894003           0.897831         0.894989        0.002040   \n",
       "22           0.894373           0.898310         0.894877        0.002622   \n",
       "1            0.893946           0.898912         0.894719        0.003156   \n",
       "31           0.893168           0.897280         0.893992        0.002419   \n",
       "21           0.892058           0.896829         0.893844        0.002124   \n",
       "0            0.871263           0.878763         0.873258        0.003942   \n",
       "10           0.873295           0.877515         0.873211        0.003549   \n",
       "30           0.874652           0.873690         0.872983        0.001725   \n",
       "20           0.870171           0.877454         0.872550        0.003468   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "18                1            0.998224            0.998142   \n",
       "19                2            0.998220            0.998156   \n",
       "15                3            0.998218            0.998135   \n",
       "16                4            0.998218            0.998138   \n",
       "17                5            0.998220            0.998149   \n",
       "14                6            0.998217            0.998123   \n",
       "8                 7            0.998233            0.998146   \n",
       "37                8            0.997586            0.997522   \n",
       "7                 9            0.998235            0.998160   \n",
       "9                10            0.998222            0.998149   \n",
       "39               11            0.997612            0.997530   \n",
       "5                12            0.998212            0.998163   \n",
       "6                13            0.998224            0.998138   \n",
       "38               14            0.997599            0.997565   \n",
       "13               15            0.998186            0.998137   \n",
       "3                16            0.998217            0.998103   \n",
       "36               17            0.997618            0.997529   \n",
       "35               18            0.997588            0.997556   \n",
       "4                19            0.998234            0.998133   \n",
       "34               20            0.997561            0.997509   \n",
       "12               21            0.998169            0.998089   \n",
       "32               22            0.997497            0.997456   \n",
       "33               23            0.997509            0.997536   \n",
       "27               24            0.997605            0.997531   \n",
       "28               25            0.997576            0.997559   \n",
       "2                26            0.998192            0.998102   \n",
       "29               27            0.997628            0.997547   \n",
       "24               28            0.997582            0.997527   \n",
       "26               29            0.997602            0.997551   \n",
       "25               30            0.997587            0.997531   \n",
       "11               31            0.998149            0.998056   \n",
       "23               32            0.997505            0.997506   \n",
       "22               33            0.997533            0.997467   \n",
       "1                34            0.998134            0.998067   \n",
       "31               35            0.997469            0.997402   \n",
       "21               36            0.997466            0.997402   \n",
       "0                37            0.996156            0.996127   \n",
       "10               38            0.996071            0.995992   \n",
       "30               39            0.995222            0.994677   \n",
       "20               40            0.994849            0.994716   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "18            0.998036          0.998134         0.000077  \n",
       "19            0.998026          0.998134         0.000080  \n",
       "15            0.998015          0.998123         0.000084  \n",
       "16            0.998057          0.998137         0.000066  \n",
       "17            0.998049          0.998139         0.000070  \n",
       "14            0.998014          0.998118         0.000083  \n",
       "8             0.998057          0.998145         0.000072  \n",
       "37            0.997051          0.997386         0.000239  \n",
       "7             0.998052          0.998149         0.000075  \n",
       "9             0.998031          0.998134         0.000079  \n",
       "39            0.997057          0.997400         0.000245  \n",
       "5             0.998043          0.998139         0.000071  \n",
       "6             0.998057          0.998140         0.000068  \n",
       "38            0.997072          0.997412         0.000241  \n",
       "13            0.998007          0.998110         0.000075  \n",
       "3             0.997994          0.998105         0.000091  \n",
       "36            0.997074          0.997407         0.000238  \n",
       "35            0.997006          0.997383         0.000267  \n",
       "4             0.998063          0.998143         0.000070  \n",
       "34            0.997039          0.997369         0.000235  \n",
       "12            0.997965          0.998074         0.000084  \n",
       "32            0.996982          0.997311         0.000234  \n",
       "33            0.997003          0.997350         0.000245  \n",
       "27            0.997038          0.997391         0.000251  \n",
       "28            0.997044          0.997393         0.000247  \n",
       "2             0.998023          0.998106         0.000069  \n",
       "29            0.997054          0.997409         0.000254  \n",
       "24            0.996987          0.997365         0.000269  \n",
       "26            0.997068          0.997407         0.000240  \n",
       "25            0.997058          0.997392         0.000237  \n",
       "11            0.997913          0.998039         0.000097  \n",
       "23            0.997020          0.997344         0.000229  \n",
       "22            0.997037          0.997346         0.000220  \n",
       "1             0.997907          0.998036         0.000095  \n",
       "31            0.996901          0.997257         0.000253  \n",
       "21            0.996893          0.997254         0.000256  \n",
       "0             0.995481          0.995921         0.000312  \n",
       "10            0.995911          0.995991         0.000065  \n",
       "30            0.994785          0.994894         0.000236  \n",
       "20            0.994638          0.994734         0.000087  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values(by=\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` al estar ajustado se convierte en un estimador, por lo cual podemos usar el método predict, por debajo simplemente se usará el mejor estimador `grid.best_estimator_`. \n",
    "\n",
    "Para añadir el funcionamiento del mejor estimador obtenido por el modelo con nuestra funcion `evaluar_modelo` no usamos el objeto grid en si, ya que la funcion `cross_validate` hace multiples ajustes y evaluaciones (volveriamos a esperar los 8 minutos que a tardado un ajuste multiplicado por el número de validaciones cruzadas!).\n",
    "\n",
    "Para evaluar el funcionamiento del mejor estimador simplemente usamos la funcion con el mejor estimador directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultados[\"rf_gridsearch\"] = evaluar_modelo(grid.best_estimator_, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ahora vamos a realizar la misma optimización de parámetros pero usando `RandomizedSearchCV`. RandomizedSearchCV funciona de forma similar a GridSearchCV, pero en vez de evaluar todas las combinaciones posibles de hiperparámetros, se toman n muestras de hiperparámetros de dichas distribuciones.\n",
    "\n",
    "Se recomienda usar distribuciones en vez de valores fijos para hiperparámetros continuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a evaluar el funcionamiento de la busqueda aleatoria con los mísmos hiperparámetros que hemos usado en la busqueda en malla. Para `RandomizedSearchCV` tenemos que indicarle cuantas variantes de hiperparámetros utilizar (definidas por el parámetro n_iter, por defecto toma 10 variantes). Dado que dicha búsqueda toma muestreos el parámetro ya no se llama `param_grid` sino `param_distributions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_random = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=parametros_busqueda_rf,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15min 46s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda con 10 iteraciones ha tardado 1min 25s en mi máquina. Veamos como ha funcionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8968929619020128\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=560, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random.best_score_)\n",
    "print(busqueda_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de malla obtuvo un ROC AUC máximo de 0.89726431782 versus 0.896926092788 obtenido por la búsqueda aleatoria. Sin embargo la busqueda aleatoria ha tardado 8 veces menos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch\"] = evaluar_modelo(grid.best_estimator_, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una ventaja del Randomized Search es que nos permite evaluar un espacio de hiperparámetros más amplio para un tiempo de computación similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver esto vamos a ampliar el espacio de búsqueda de hiperparámetros y hacer 100 muestreos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "param_dist_random = {\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": sp_randint(1, 11),\n",
    "    \"min_samples_split\": sp_randint(2, 11),\n",
    "    \"min_samples_leaf\": sp_randint(1, 11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": np.linspace(10,1000,10).astype(int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_random_100 = RandomizedSearchCV(estimator=estimador_rf, \n",
    "                    param_distributions=param_dist_random,\n",
    "                   scoring=\"roc_auc\", n_jobs=-1, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alfy\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13min 46s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_random_100.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi máquina esta búsqueda ha tardado 8 minutos 54 segundos, un poco más que el grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9193261285855976\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=10,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_random_100.best_score_)\n",
    "print(busqueda_random_100.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La búsqueda aleatoria con los nuevos parámetros ha tardado un tiempo similar a la busqueda en malla, pero ha obtenido una puntuación máxima ROC AUC de 0.91950285418 (versus 0.89726431782 de la busqueda en malla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch_100\"] = evaluar_modelo(busqueda_random_100.best_estimator_,\n",
    "                                                      X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el estimador obtenido con la búsqueda aleatoria es el que mejor funciona.\n",
    "\n",
    "En general, salvo que el espacio de hiperparámetros que queramos explorar sea pequeño, es mejor el utilizar `RandomizedSearchCV` en vez de `GridSearchCV`. Esto es así por que en general no existe un unico conjunto de hiperparámetros que obtiene el mejor funcionamiento, sino que suelen existir multiples \"areas\" en el espacio dimensional de los hiperparámetros que funcionan de forma similar. Al hacer una búsqueda aleatoria podemos explorar las diversas areas en un tiempo más reducido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
